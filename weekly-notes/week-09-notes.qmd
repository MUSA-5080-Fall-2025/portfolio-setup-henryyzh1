---
title: "Week 9 Notes - Critical Perspectives on Predictive Policing"
date: "2025-11-03"
---

## Key Concepts Learned
- Introduced the idea of **“dirty data”** — biased, incomplete, or manipulated police data.  
- Learned how predictive policing can reproduce systemic inequality.  
- Reviewed case studies (Chicago, Baltimore, NYPD) showing **data manipulation and feedback loops**.  
- Discussed the limits of technical fixes: bias mitigation ≠ justice.  
- Compared **Poisson vs. Negative Binomial** models for crime counts.  
- Understood that **“accuracy” and “fairness”** are not the same.  

## Coding Techniques
- Created **fishnet grids (500m)** and aggregated crime points to cells.  
- Calculated **Local Moran’s I** for hotspots using `spdep`.  
- Built **Poisson and Negative Binomial** models with `glm()` and `glm.nb()`.  
- Implemented **spatial cross-validation (LOGO-CV)** to avoid spatial leakage.  
- Compared model results with **Kernel Density Estimation (KDE)** baseline.  

## Questions & Challenges
- Can “cleaning” biased data ever make predictive policing fair?  
- What counts as “neutral” or “objective” crime data?  
- How should accuracy be balanced against social harm?  
- What does it mean to validate a model that may reinforce injustice?  

## Connections to Policy
- Highlights how **data-driven policing can amplify inequality**.  
- Emphasizes need for **transparency and accountability** in algorithmic decisions.  
- Suggests shifting predictive models toward **social service allocation**, not surveillance.  
- Aligns with ethical urban data governance and **community trust-building**.  

## Reflection
- Realized predictive models can be **technically sound yet socially harmful**.  
- Found the “dirty data” concept essential for **critical data literacy**.  
- The lecture reframed prediction as a **political and ethical act**, not just technical.  
- Important takeaway: predictive tools must **serve justice, not just efficiency**.  