{
  "hash": "3129227e3c2598cbd80e0b925acca622",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 5: Space-Time Modeling\"\nsubtitle: \"Bike Share Rebalancing for Philadelphia Indego\"\nauthor: \"Jinheng Cen, Henry Yang\"\ndate: 11/27/2025\noutput: \n  html_document:\n    toc: true\n    toc_float: true\n    code_folding: show\n    code_download: true\neditor_options: \n  markdown: \n    wrap: 72\n---\n\n\n\n---\n\n# Setup\n\n## Load Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# here!\nlibrary(here)\n# Get rid of scientific notation. We gotta look good!\noptions(scipen = 999)\n```\n:::\n\n\n## Define Themes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n\n\n------------------------------------------------------------------------\n\n# Data Import & Preparation\n\n## Load Indego Trip Data (Q2 2025)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read Q1 2024 data\nindego <- read_csv(here(\"data\", \"indego-trips-2024-q2.csv\"))\n\n# Quick look at the data\n#glimpse(indego)\n```\n:::\n\n\n## Examine the Data Structure\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# How many trips?\ncat(\"Total trips in Q2 2024:\", nrow(indego), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal trips in Q2 2024: 368091 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Date range\ncat(\"Date range:\", \n    min(mdy_hm(indego$start_time)), \"to\", \n    max(mdy_hm(indego$start_time)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDate range: 1711929600 to 1719791760 \n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego$start_station)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnique start stations: 255 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Trip types\ntable(indego$trip_route_category)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   One Way Round Trip \n    342299      25792 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Passholder types\ntable(indego$passholder_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n Day Pass  Indego30 Indego365 \n    20926    231909    115256 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Bike types\ntable(indego$bike_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nelectric standard \n  216497   151594 \n```\n\n\n:::\n:::\n\n\n## Create Time Bins\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Look at temporal features\nhead(indego %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  start_datetime      interval60           week dotw   hour weekend\n  <dttm>              <dttm>              <dbl> <ord> <int>   <dbl>\n1 2024-04-01 00:00:00 2024-04-01 00:00:00    14 Mon       0       0\n2 2024-04-01 00:03:00 2024-04-01 00:00:00    14 Mon       0       0\n3 2024-04-01 00:04:00 2024-04-01 00:00:00    14 Mon       0       0\n4 2024-04-01 00:04:00 2024-04-01 00:00:00    14 Mon       0       0\n5 2024-04-01 00:06:00 2024-04-01 00:00:00    14 Mon       0       0\n6 2024-04-01 00:07:00 2024-04-01 00:00:00    14 Mon       0       0\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Exploratory Analysis\n\n## Trips Over Time\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daily trip counts\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q2 2024\",\n    subtitle = \"Winter demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/trips_over_time-1.png){width=672}\n:::\n:::\n\n\n**Question:** What patterns do you see? How does ridership change over\ntime?\n\n- Ridership fluctuates within a certain range but continues to grow.\n\n## Hourly Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/hourly_patterns-1.png){width=672}\n:::\n:::\n\n\n**Question:** When are the peak hours? How do weekends differ from\nweekdays?\n\n- There are two peak hours on weekdays: 8-9 a.m. and 4-7 p.m. There is one\npeak hour on weekends: 2-6 p.m.The number of trips during peak hours on\nweekdays is significantly higher, and the changes are more sudden.\n\n## Top Stations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(20)\n\nkable(top_stations, \n      caption = \"Top 20 Indego Stations by Trip Origins\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Top 20 Indego Stations by Trip Origins</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> start_station </th>\n   <th style=\"text-align:right;\"> start_lat </th>\n   <th style=\"text-align:right;\"> start_lon </th>\n   <th style=\"text-align:right;\"> trips </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 3,010 </td>\n   <td style=\"text-align:right;\"> 39.94711 </td>\n   <td style=\"text-align:right;\"> -75.16618 </td>\n   <td style=\"text-align:right;\"> 6,115 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,032 </td>\n   <td style=\"text-align:right;\"> 39.94527 </td>\n   <td style=\"text-align:right;\"> -75.17971 </td>\n   <td style=\"text-align:right;\"> 5,231 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,295 </td>\n   <td style=\"text-align:right;\"> 39.95028 </td>\n   <td style=\"text-align:right;\"> -75.16027 </td>\n   <td style=\"text-align:right;\"> 4,451 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,359 </td>\n   <td style=\"text-align:right;\"> 39.94888 </td>\n   <td style=\"text-align:right;\"> -75.16978 </td>\n   <td style=\"text-align:right;\"> 4,248 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,022 </td>\n   <td style=\"text-align:right;\"> 39.95472 </td>\n   <td style=\"text-align:right;\"> -75.18323 </td>\n   <td style=\"text-align:right;\"> 4,070 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,028 </td>\n   <td style=\"text-align:right;\"> 39.94061 </td>\n   <td style=\"text-align:right;\"> -75.14958 </td>\n   <td style=\"text-align:right;\"> 4,052 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,066 </td>\n   <td style=\"text-align:right;\"> 39.94561 </td>\n   <td style=\"text-align:right;\"> -75.17348 </td>\n   <td style=\"text-align:right;\"> 4,047 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,054 </td>\n   <td style=\"text-align:right;\"> 39.96250 </td>\n   <td style=\"text-align:right;\"> -75.17420 </td>\n   <td style=\"text-align:right;\"> 3,847 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,020 </td>\n   <td style=\"text-align:right;\"> 39.94855 </td>\n   <td style=\"text-align:right;\"> -75.19007 </td>\n   <td style=\"text-align:right;\"> 3,792 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,208 </td>\n   <td style=\"text-align:right;\"> 39.95048 </td>\n   <td style=\"text-align:right;\"> -75.19324 </td>\n   <td style=\"text-align:right;\"> 3,661 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,052 </td>\n   <td style=\"text-align:right;\"> 39.94732 </td>\n   <td style=\"text-align:right;\"> -75.15695 </td>\n   <td style=\"text-align:right;\"> 3,651 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,012 </td>\n   <td style=\"text-align:right;\"> 39.94218 </td>\n   <td style=\"text-align:right;\"> -75.17747 </td>\n   <td style=\"text-align:right;\"> 3,573 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,163 </td>\n   <td style=\"text-align:right;\"> 39.94974 </td>\n   <td style=\"text-align:right;\"> -75.18097 </td>\n   <td style=\"text-align:right;\"> 3,558 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,244 </td>\n   <td style=\"text-align:right;\"> 39.93865 </td>\n   <td style=\"text-align:right;\"> -75.16674 </td>\n   <td style=\"text-align:right;\"> 3,549 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,185 </td>\n   <td style=\"text-align:right;\"> 39.95169 </td>\n   <td style=\"text-align:right;\"> -75.15888 </td>\n   <td style=\"text-align:right;\"> 3,523 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,007 </td>\n   <td style=\"text-align:right;\"> 39.94517 </td>\n   <td style=\"text-align:right;\"> -75.15993 </td>\n   <td style=\"text-align:right;\"> 3,492 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,059 </td>\n   <td style=\"text-align:right;\"> 39.96244 </td>\n   <td style=\"text-align:right;\"> -75.16121 </td>\n   <td style=\"text-align:right;\"> 3,470 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,362 </td>\n   <td style=\"text-align:right;\"> 39.94816 </td>\n   <td style=\"text-align:right;\"> -75.16226 </td>\n   <td style=\"text-align:right;\"> 3,443 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,101 </td>\n   <td style=\"text-align:right;\"> 39.94295 </td>\n   <td style=\"text-align:right;\"> -75.15955 </td>\n   <td style=\"text-align:right;\"> 3,425 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,063 </td>\n   <td style=\"text-align:right;\"> 39.94633 </td>\n   <td style=\"text-align:right;\"> -75.16980 </td>\n   <td style=\"text-align:right;\"> 3,404 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Get Philadelphia Spatial Context\n\n## Load Philadelphia Census Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\",\n  progress = \"FALSE\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n\n# Check the data\n#glimpse(philly_census)\n```\n:::\n\n\n## Map Philadelphia Context\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/map_philly-1.png){width=672}\n:::\n:::\n\n\n## Join Census Data to Stations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/join_census_to_stations-1.png){width=672}\n:::\n:::\n\n\n# Dealing with missing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n# Get Weather Data\n\nWeather significantly affects bike share demand.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q1 2025: January 1 - March 31\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-04-01\",\n  date_end = \"2024-06-30\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation       Wind_Speed    \n Min.   :37.00   Min.   :0.00000   Min.   : 0.000  \n 1st Qu.:54.00   1st Qu.:0.00000   1st Qu.: 5.000  \n Median :66.00   Median :0.00000   Median : 7.000  \n Mean   :65.05   Mean   :0.00794   Mean   : 7.677  \n 3rd Qu.:74.00   3rd Qu.:0.00000   3rd Qu.:10.000  \n Max.   :98.00   Max.   :1.05000   Max.   :30.000  \n```\n\n\n:::\n:::\n\n\n## Visualize Weather Patterns\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q2 2024\",\n    subtitle = \"Spring to early summer transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/visualize_weather-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Create Space-Time Panel\n\n## Aggregate Trips to Station-Hour Level\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n\n# How many station-hour observations?\nnrow(trips_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 175936\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\nlength(unique(trips_panel$start_station))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 235\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique hours?\nlength(unique(trips_panel$interval60))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2184\n```\n\n\n:::\n:::\n\n\n## Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel**\nwhere every station-hour combination exists (even if Trip_Count = 0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows, big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected panel rows: 513,240 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Current rows:\", format(nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCurrent rows: 175,936 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Missing rows:\", format(expected_rows - nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMissing rows: 337,304 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n\n# Verify we have complete panel\ncat(\"Complete panel rows:\", format(nrow(study_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nComplete panel rows: 513,240 \n```\n\n\n:::\n:::\n\n\n## Add Time Features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n## Join Weather Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature    Precipitation  \n Min.   : 0.0000   Min.   :37.00   Min.   :0.000  \n 1st Qu.: 0.0000   1st Qu.:54.00   1st Qu.:0.000  \n Median : 0.0000   Median :66.00   Median :0.000  \n Mean   : 0.6415   Mean   :65.05   Mean   :0.008  \n 3rd Qu.: 1.0000   3rd Qu.:74.00   3rd Qu.:0.000  \n Max.   :22.0000   Max.   :98.00   Max.   :1.050  \n                   NA's   :5640    NA's   :5640   \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Create Temporal Lag Variables\n\nThe key innovation for space-time prediction: **past demand predicts\nfuture demand**.\n\n## Why Lags?\n\nIf there were 15 bike trips from Station A at 8:00 AM, there will\nprobably be \\~15 trips at 9:00 AM. We can use this temporal persistence\nto improve predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows after removing NA lags: 632,150 \n```\n\n\n:::\n:::\n\n\n## Visualize Lag Correlations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/lag_correlations-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Temporal Train/Test Split\n\n**CRITICAL:** We must train on PAST data and test on FUTURE data!\n\n## Why Temporal Validation Matters\n\nIn real operations, at 6:00 AM on March 15, we need to predict demand\nfor March 15-31. We have data from Jan 1 - March 14, but NOT from March\n15-31 (it hasn't happened yet!).\n\n**Wrong approach:** Train on weeks 10-13, test on weeks 1-9 (predicting\npast from future!)\n\n**Correct approach:** Train on weeks 1-9, test on weeks 10-13\n(predicting future from past)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Split by week\n# Q2 has weeks 1-13 (Jan-Mar)14-26\n# Train on weeks 1-9 (Jan 1 - early March)14-23\n# Test on weeks 10-13 (rest of March)23-26\n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 23) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 23) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 23)\n\ntest <- study_panel_complete %>%\n  filter(week >= 23)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations: 447,528 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations: 176,552 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining date range: 19814 to 19876 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting date range: 19877 to 19904 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Build Predictive Models\n\n## Model 1: Baseline (Time + Weather)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7197 -0.6759 -0.2053  0.1850 20.6050 \n\nCoefficients:\n                   Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.623380   0.014322 -43.527 < 0.0000000000000002 ***\nas.factor(hour)1  -0.072867   0.011938  -6.104 0.000000001037041260 ***\nas.factor(hour)2  -0.100186   0.011862  -8.446 < 0.0000000000000002 ***\nas.factor(hour)3  -0.101366   0.011827  -8.571 < 0.0000000000000002 ***\nas.factor(hour)4  -0.098172   0.011994  -8.185 0.000000000000000272 ***\nas.factor(hour)5   0.031520   0.011964   2.635             0.008424 ** \nas.factor(hour)6   0.251304   0.011708  21.464 < 0.0000000000000002 ***\nas.factor(hour)7   0.539861   0.011720  46.065 < 0.0000000000000002 ***\nas.factor(hour)8   0.854340   0.011759  72.652 < 0.0000000000000002 ***\nas.factor(hour)9   0.645589   0.011734  55.020 < 0.0000000000000002 ***\nas.factor(hour)10  0.548414   0.011459  47.857 < 0.0000000000000002 ***\nas.factor(hour)11  0.579472   0.011564  50.111 < 0.0000000000000002 ***\nas.factor(hour)12  0.626987   0.011257  55.699 < 0.0000000000000002 ***\nas.factor(hour)13  0.623662   0.011744  53.104 < 0.0000000000000002 ***\nas.factor(hour)14  0.656044   0.011488  57.107 < 0.0000000000000002 ***\nas.factor(hour)15  0.760629   0.011788  64.526 < 0.0000000000000002 ***\nas.factor(hour)16  0.862528   0.011435  75.426 < 0.0000000000000002 ***\nas.factor(hour)17  1.157733   0.011763  98.420 < 0.0000000000000002 ***\nas.factor(hour)18  0.930235   0.011977  77.668 < 0.0000000000000002 ***\nas.factor(hour)19  0.681722   0.011792  57.813 < 0.0000000000000002 ***\nas.factor(hour)20  0.432304   0.011798  36.642 < 0.0000000000000002 ***\nas.factor(hour)21  0.269929   0.011696  23.078 < 0.0000000000000002 ***\nas.factor(hour)22  0.191038   0.011726  16.291 < 0.0000000000000002 ***\nas.factor(hour)23  0.069112   0.011871   5.822 0.000000005812931084 ***\ndotw_simple2       0.061945   0.006312   9.814 < 0.0000000000000002 ***\ndotw_simple3       0.021134   0.006089   3.471             0.000519 ***\ndotw_simple4       0.103407   0.006324  16.352 < 0.0000000000000002 ***\ndotw_simple5       0.057970   0.006276   9.237 < 0.0000000000000002 ***\ndotw_simple6       0.007771   0.006527   1.191             0.233767    \ndotw_simple7      -0.034128   0.006504  -5.247 0.000000154440328777 ***\nTemperature        0.012729   0.000171  74.419 < 0.0000000000000002 ***\nPrecipitation     -2.054152   0.062168 -33.042 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.117 on 447496 degrees of freedom\nMultiple R-squared:  0.1143,\tAdjusted R-squared:  0.1142 \nF-statistic:  1863 on 31 and 447496 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\nThe model uses Monday as the baseline. Each coefficient represents the\ndifference in expected trips per station-hour compared to Monday -\ndow_simple2 = Tuesday..\n\n**Weekday Pattern (Tue-Fri):**\n\n-   All weekdays have positive coefficients (0.029 to 0.052)\n-   Tuesday has the highest weekday effect (+0.052)\n-   Weekdays likely benefit from concentrated commuting patterns\n\n**Weekend Pattern (Sat-Sun):**\n\n-   Both weekend days have negative coefficients (-0.061 and -0.065)\n-   This means FEWER trips per station-hour than Monday\n\n**Hourly Interpretation**\n\nHour Coefficient Interpretation 0 (baseline) 0.000 trips/hour (midnight)\n1 -0.018 slightly fewer than midnight ... 6 +0.151 morning activity\nstarting 7 +0.276 morning rush building 8 +0.487 PEAK morning rush 9\n+0.350 post-rush ... 17 +0.568 PEAK evening rush (5 PM!) 18 +0.389\nevening declining ... 23 +0.034 late night minimal\n\n## Model 2: Add Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.1097 -0.4314 -0.1254  0.1217 17.3211 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.2516703  0.0123654 -20.353 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0315610  0.0102751  -3.072             0.002129 ** \nas.factor(hour)2  -0.0255020  0.0102137  -2.497             0.012531 *  \nas.factor(hour)3  -0.0193838  0.0101872  -1.903             0.057071 .  \nas.factor(hour)4  -0.0118938  0.0103351  -1.151             0.249811    \nas.factor(hour)5   0.0879106  0.0103161   8.522 < 0.0000000000000002 ***\nas.factor(hour)6   0.2413446  0.0101023  23.890 < 0.0000000000000002 ***\nas.factor(hour)7   0.3912950  0.0101257  38.644 < 0.0000000000000002 ***\nas.factor(hour)8   0.5751810  0.0101693  56.561 < 0.0000000000000002 ***\nas.factor(hour)9   0.2586771  0.0101578  25.466 < 0.0000000000000002 ***\nas.factor(hour)10  0.2239928  0.0099018  22.621 < 0.0000000000000002 ***\nas.factor(hour)11  0.2750789  0.0099905  27.534 < 0.0000000000000002 ***\nas.factor(hour)12  0.3434636  0.0097188  35.340 < 0.0000000000000002 ***\nas.factor(hour)13  0.3325602  0.0101359  32.810 < 0.0000000000000002 ***\nas.factor(hour)14  0.3735677  0.0099128  37.686 < 0.0000000000000002 ***\nas.factor(hour)15  0.4382105  0.0101782  43.054 < 0.0000000000000002 ***\nas.factor(hour)16  0.5186079  0.0098810  52.485 < 0.0000000000000002 ***\nas.factor(hour)17  0.7372223  0.0101810  72.412 < 0.0000000000000002 ***\nas.factor(hour)18  0.3982131  0.0103986  38.295 < 0.0000000000000002 ***\nas.factor(hour)19  0.2607371  0.0102099  25.538 < 0.0000000000000002 ***\nas.factor(hour)20  0.1041311  0.0102076  10.201 < 0.0000000000000002 ***\nas.factor(hour)21  0.0773039  0.0100888   7.662  0.00000000000001829 ***\nas.factor(hour)22  0.0804148  0.0100993   7.962  0.00000000000000169 ***\nas.factor(hour)23  0.0141841  0.0102172   1.388             0.165062    \ndotw_simple2       0.0186587  0.0054346   3.433             0.000596 ***\ndotw_simple3      -0.0004020  0.0052441  -0.077             0.938896    \ndotw_simple4       0.0308340  0.0054469   5.661  0.00000001507660401 ***\ndotw_simple5       0.0029701  0.0054080   0.549             0.582861    \ndotw_simple6      -0.0249257  0.0056246  -4.432  0.00000935943656590 ***\ndotw_simple7      -0.0338659  0.0055995  -6.048  0.00000000146779797 ***\nTemperature        0.0037869  0.0001493  25.370 < 0.0000000000000002 ***\nPrecipitation     -0.9449920  0.0535786 -17.637 < 0.0000000000000002 ***\nlag1Hour           0.4030038  0.0013966 288.563 < 0.0000000000000002 ***\nlag3Hours          0.1234155  0.0013804  89.408 < 0.0000000000000002 ***\nlag1day            0.1253160  0.0012810  97.830 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.961 on 447493 degrees of freedom\nMultiple R-squared:  0.344,\tAdjusted R-squared:  0.344 \nF-statistic:  6903 on 34 and 447493 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Question:** Did adding lags improve R²? Why or why not?\n\nAdding lags increases R² from 0.07592 to 0.2518. This is because past\nusage patterns influence future patterns.\n\n## Model 3: Add Demographics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\n\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + Med_Inc.x + \n    Percent_Taking_Transit.y + Percent_White.y, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.0962 -0.6781 -0.2691  0.4234 17.2038 \n\nCoefficients:\n                              Estimate    Std. Error t value\n(Intercept)               0.3857918409  0.0371091868  10.396\nas.factor(hour)1         -0.0021036158  0.0412694199  -0.051\nas.factor(hour)2         -0.0088620570  0.0469025109  -0.189\nas.factor(hour)3         -0.0851082042  0.0529075781  -1.609\nas.factor(hour)4         -0.1044632428  0.0557223076  -1.875\nas.factor(hour)5          0.0516286807  0.0371091993   1.391\nas.factor(hour)6          0.2505851189  0.0312856619   8.010\nas.factor(hour)7          0.4005664111  0.0294980575  13.579\nas.factor(hour)8          0.6170072423  0.0287282776  21.477\nas.factor(hour)9          0.1382271180  0.0288552539   4.790\nas.factor(hour)10         0.1084529302  0.0287107985   3.777\nas.factor(hour)11         0.1546773002  0.0286616605   5.397\nas.factor(hour)12         0.2287878417  0.0281439459   8.129\nas.factor(hour)13         0.2593480167  0.0286602368   9.049\nas.factor(hour)14         0.2789001366  0.0282806593   9.862\nas.factor(hour)15         0.3576516996  0.0284181466  12.585\nas.factor(hour)16         0.4807434184  0.0279992423  17.170\nas.factor(hour)17         0.8226919934  0.0281755098  29.199\nas.factor(hour)18         0.3568673063  0.0285563485  12.497\nas.factor(hour)19         0.1776173104  0.0286237376   6.205\nas.factor(hour)20         0.0116961313  0.0293501783   0.399\nas.factor(hour)21         0.0203613434  0.0299654314   0.679\nas.factor(hour)22         0.0304705944  0.0307099983   0.992\nas.factor(hour)23        -0.0160285584  0.0326523113  -0.491\ndotw_simple2              0.0547342235  0.0119297080   4.588\ndotw_simple3              0.0108137555  0.0116378166   0.929\ndotw_simple4              0.0381015979  0.0117220832   3.250\ndotw_simple5              0.0054589733  0.0118327085   0.461\ndotw_simple6              0.0459381855  0.0125566250   3.658\ndotw_simple7              0.0389827321  0.0126414408   3.084\nTemperature               0.0075088185  0.0003400333  22.083\nPrecipitation            -2.1950253458  0.1294673174 -16.954\nlag1Hour                  0.2941552792  0.0022571175 130.323\nlag3Hours                 0.0851609125  0.0023233110  36.655\nlag1day                   0.0958710202  0.0022118269  43.345\nMed_Inc.x                 0.0000001627  0.0000001133   1.435\nPercent_Taking_Transit.y -0.0032455105  0.0004140532  -7.838\nPercent_White.y           0.0032869902  0.0002079131  15.809\n                                     Pr(>|t|)    \n(Intercept)              < 0.0000000000000002 ***\nas.factor(hour)1                     0.959347    \nas.factor(hour)2                     0.850135    \nas.factor(hour)3                     0.107702    \nas.factor(hour)4                     0.060834 .  \nas.factor(hour)5                     0.164148    \nas.factor(hour)6         0.000000000000001159 ***\nas.factor(hour)7         < 0.0000000000000002 ***\nas.factor(hour)8         < 0.0000000000000002 ***\nas.factor(hour)9         0.000001666444693928 ***\nas.factor(hour)10                    0.000159 ***\nas.factor(hour)11        0.000000067997969457 ***\nas.factor(hour)12        0.000000000000000435 ***\nas.factor(hour)13        < 0.0000000000000002 ***\nas.factor(hour)14        < 0.0000000000000002 ***\nas.factor(hour)15        < 0.0000000000000002 ***\nas.factor(hour)16        < 0.0000000000000002 ***\nas.factor(hour)17        < 0.0000000000000002 ***\nas.factor(hour)18        < 0.0000000000000002 ***\nas.factor(hour)19        0.000000000547584341 ***\nas.factor(hour)20                    0.690260    \nas.factor(hour)21                    0.496826    \nas.factor(hour)22                    0.321099    \nas.factor(hour)23                    0.623508    \ndotw_simple2             0.000004477560354566 ***\ndotw_simple3                         0.352792    \ndotw_simple4                         0.001153 ** \ndotw_simple5                         0.644551    \ndotw_simple6                         0.000254 ***\ndotw_simple7                         0.002045 ** \nTemperature              < 0.0000000000000002 ***\nPrecipitation            < 0.0000000000000002 ***\nlag1Hour                 < 0.0000000000000002 ***\nlag3Hours                < 0.0000000000000002 ***\nlag1day                  < 0.0000000000000002 ***\nMed_Inc.x                            0.151217    \nPercent_Taking_Transit.y 0.000000000000004594 ***\nPercent_White.y          < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.221 on 145195 degrees of freedom\n  (302295 observations deleted due to missingness)\nMultiple R-squared:  0.2319,\tAdjusted R-squared:  0.2317 \nF-statistic:  1185 on 37 and 145195 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n## Model 4: Add Station Fixed Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.259619 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.2582656 \n```\n\n\n:::\n:::\n\n\n**What do station fixed effects capture?** Baseline differences in\ndemand across stations (some are just busier than others!).\n\n## Model 5: Add Rush Hour Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n\ncat(\"Model 5 R-squared:\", summary(model5)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.2635307 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.2621691 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Model Evaluation\n\n## Calculate Predictions and MAE\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get predictions on test set\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.87 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.97 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.95 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.95 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Visualize Model Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/compare_models-1.png){width=672}\n:::\n:::\n\n\n3.  **Compare results** to Q1 2025:\n\n    -   How do MAE values compare? Why might they differ?\n    -   Are temporal patterns different (e.g., summer vs. winter)?\n    -   Which features are most important in your quarter?\n\n**Answer:**\n\n-   All models of Q2 2024 have higher MAE value compared with Q1 2025.\n    MAE values (Q2 2024 vs Q1 2025) from lowest to highest are: Model 2\n    Temporal Lags (0.71 vs 0.5), Model 1 Time + Weather (0.87 vs 0.6),\n    Model 4 Station FE (0.95 vs 0.73), Model 5 Rush Hour Interaction\n    (0.95 vs 0.73), Model 3 Demographics (0.97 vs 0.74)\n-   MAE will be larger in summer because warmer weather leads to\n    increased usage of shared bicycles. Higher usage introduces greater\n    uncertainty, resulting in larger errors.\n-   Similar to Q1 2025, temporal is the most important feature in our\n    quarter.\n\n------------------------------------------------------------------------\n\n# Space-Time Error Analysis\n\n## Observed vs. Predicted\n\nUse our best model (Model 2) for error analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/obs_vs_pred-1.png){width=672}\n:::\n:::\n\n\n**Question:** Where is the model performing well? Where is it\nstruggling?\n\nPerforming well: AM Rush, Evening, Struggling: Overnight, PM Rush\n\n## Spatial Error Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon, y = start_lat, color = MAE),\n    size = 1,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Higher in Center City\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 1,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg\\nDemand\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 1,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand  \np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 1,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hour)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/spatial_errors-1.png){width=672}\n:::\n\n```{.r .cell-code}\np1\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/spatial_errors-2.png){width=672}\n:::\n:::\n\n\n**Question:** Hypothesize why (missing features? different demand patterns?)\n\n**Answer:**\n\n-   Neighborhoods in city center have high errors\n-   Because stations in the city center have higher average demand.\n    Higher usage brings significant uncertainty. Usage patterns may be\n    influenced by numerous factors beyond the variables selected in our\n    model.\n\n## Temporal Error Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/temporal_errors-1.png){width=672}\n:::\n:::\n\n\n**Question:**\n\n-   When are errors highest?\n-   Do certain hours/days have systematic under/over-prediction?\n-   Are there seasonal patterns?\n\n**Answer:**\n\n-   PM Rush has the highest errors.\n-   Weekday has relatively higher errors than weekend\n-   Summer (warmer season) has higher errors\n\n## Errors and Demographics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Cen_Yang_Assignment5_files/figure-html/errors_demographics-1.png){width=672}\n:::\n:::\n\n\n**Critical Question:** \n-   Are certain communities systematically harder to predict?\n-   What are the equity implications?\n\n**Answer:**\n\n-   Neighborhoods with higher income levels, higher percentage of public\n    transit, and higher percentage of white people are harder to predict\n    (higher MAE)\n-   Although these neighborhoods are not traditionally considered\n    disadvantaged communities, the model's inaccuracies can negatively\n    impact the user experience.Some potential users of shared bicycles\n    may be forced to drive due to insufficient bike availability,\n    thereby increasing energy waste. Or deploying large numbers of bikes\n    in car-oriented neighborhoods，which leads to inefficient\n    operations.\n\n---\n\n# Adding more features\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add rolling 7-day average and same-hour-last-week demand by station\nstudy_panel_enhanced <- study_panel_complete %>%\n  group_by(start_station) %>%\n  arrange(interval60, .by_group = TRUE) %>%\n  mutate(\n    rolling7day = as.numeric(stats::filter(Trip_Count, rep(1 / 168, 168), sides = 1)),\n    same_hour_last_week = lag(Trip_Count, 24 * 7)\n  ) %>%\n  ungroup() %>%\n  filter(!is.na(rolling7day), !is.na(same_hour_last_week))\n\n# Recreate temporal train/test split with new features\ntrain_enh <- study_panel_enhanced %>% filter(week < 23)\ntest_enh <- study_panel_enhanced %>% filter(week >= 23)\n\n# Day-of-week factor coding\ntrain_enh <- train_enh %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\ncontrasts(train_enh$dotw_simple) <- contr.treatment(7)\n\ntest_enh <- test_enh %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\ncontrasts(test_enh$dotw_simple) <- contr.treatment(7)\n\n# Model 2 plus the two new temporal features\nmodel2_enh <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rolling7day + same_hour_last_week,\n  data = train_enh\n)\n\nsummary(model2_enh)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + rolling7day + \n    same_hour_last_week, data = train_enh)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7762 -0.4741 -0.1198  0.2489 17.5906 \n\nCoefficients:\n                      Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)         -0.3573201  0.0139668 -25.583 < 0.0000000000000002 ***\nas.factor(hour)1    -0.0436793  0.0107732  -4.054   0.0000502662528070 ***\nas.factor(hour)2    -0.0523612  0.0108257  -4.837   0.0000013203786965 ***\nas.factor(hour)3    -0.0601095  0.0107587  -5.587   0.0000000231085947 ***\nas.factor(hour)4    -0.0490023  0.0109291  -4.484   0.0000073391903942 ***\nas.factor(hour)5     0.0672363  0.0108812   6.179   0.0000000006451743 ***\nas.factor(hour)6     0.2412399  0.0107118  22.521 < 0.0000000000000002 ***\nas.factor(hour)7     0.4123337  0.0107378  38.400 < 0.0000000000000002 ***\nas.factor(hour)8     0.6317936  0.0107524  58.759 < 0.0000000000000002 ***\nas.factor(hour)9     0.3394337  0.0107794  31.489 < 0.0000000000000002 ***\nas.factor(hour)10    0.3055771  0.0104912  29.127 < 0.0000000000000002 ***\nas.factor(hour)11    0.3667699  0.0106209  34.533 < 0.0000000000000002 ***\nas.factor(hour)12    0.4452404  0.0102915  43.263 < 0.0000000000000002 ***\nas.factor(hour)13    0.4311386  0.0106786  40.374 < 0.0000000000000002 ***\nas.factor(hour)14    0.4912939  0.0104997  46.791 < 0.0000000000000002 ***\nas.factor(hour)15    0.5651463  0.0108112  52.274 < 0.0000000000000002 ***\nas.factor(hour)16    0.6831487  0.0105573  64.708 < 0.0000000000000002 ***\nas.factor(hour)17    0.9210305  0.0109090  84.429 < 0.0000000000000002 ***\nas.factor(hour)18    0.5602527  0.0110552  50.678 < 0.0000000000000002 ***\nas.factor(hour)19    0.4049418  0.0109072  37.126 < 0.0000000000000002 ***\nas.factor(hour)20    0.2077502  0.0108717  19.109 < 0.0000000000000002 ***\nas.factor(hour)21    0.1495363  0.0107326  13.933 < 0.0000000000000002 ***\nas.factor(hour)22    0.1296927  0.0107756  12.036 < 0.0000000000000002 ***\nas.factor(hour)23    0.0406452  0.0107477   3.782             0.000156 ***\ndotw_simple2         0.0792962  0.0059509  13.325 < 0.0000000000000002 ***\ndotw_simple3         0.0477619  0.0056836   8.403 < 0.0000000000000002 ***\ndotw_simple4         0.0293298  0.0056903   5.154   0.0000002546263911 ***\ndotw_simple5        -0.0078262  0.0055809  -1.402             0.160822    \ndotw_simple6        -0.0528971  0.0057839  -9.146 < 0.0000000000000002 ***\ndotw_simple7        -0.0596471  0.0057479 -10.377 < 0.0000000000000002 ***\nTemperature          0.0013074  0.0001728   7.566   0.0000000000000386 ***\nPrecipitation       -2.9416620  0.1184383 -24.837 < 0.0000000000000002 ***\nlag1Hour             0.3333336  0.0014946 223.024 < 0.0000000000000002 ***\nlag3Hours            0.0608733  0.0014893  40.874 < 0.0000000000000002 ***\nlag1day              0.0611907  0.0014029  43.618 < 0.0000000000000002 ***\nrolling7day          0.5337144  0.0040731 131.035 < 0.0000000000000002 ***\nsame_hour_last_week -0.0071541  0.0014270  -5.013   0.0000005355246776 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9703 on 408515 degrees of freedom\nMultiple R-squared:  0.3657,\tAdjusted R-squared:  0.3657 \nF-statistic:  6543 on 36 and 408515 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predictions and MAE on the held-out set\ntest_enh <- test_enh %>%\n  mutate(pred2_enh = predict(model2_enh, newdata = test_enh))\n\nmae_model2_enh <- mean(abs(test_enh$Trip_Count - test_enh$pred2_enh), na.rm = TRUE)\ncat(\"MAE for Model 2 with new features:\", round(mae_model2_enh, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE for Model 2 with new features: 0.731 \n```\n\n\n:::\n:::\n\n\n**Question:**\n\n-   Explain *why* you chose these features\n-   Did they improve predictions? Where?\n\n**Answer:**\n\n-   We chose \"Rolling 7-day average demand\" and \"Same hour last week\" as\n    our additional features\n-   MAE remains the same but R square was improved from 0.34 to 0.36,\n    maning more data are explained in our model.\n-   We selected these features because model 2 performed best as adding\n    temporal features, so we assume that the shared bike usage pattern\n    are strongly related to temporal features.\n\n# Try poisson model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a Poisson regression using the enhanced feature set\npoisson_model <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rolling7day + same_hour_last_week,\n  data = train_enh,\n  family = poisson(link = \"log\")\n)\n\n# Predict on the held-out set and compute MAE\ntest_enh <- test_enh %>%\n  mutate(pred_poisson = predict(poisson_model, newdata = test_enh, type = \"response\"))\n\nmae_poisson <- mean(abs(test_enh$Trip_Count - test_enh$pred_poisson), na.rm = TRUE)\ncat(\"MAE for Poisson model:\", round(mae_poisson, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE for Poisson model: 0.725 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(poisson_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day + rolling7day + \n    same_hour_last_week, family = poisson(link = \"log\"), data = train_enh)\n\nCoefficients:\n                      Estimate Std. Error  z value             Pr(>|z|)    \n(Intercept)         -2.5254170  0.0233483 -108.163 < 0.0000000000000002 ***\nas.factor(hour)1    -0.5135331  0.0291059  -17.644 < 0.0000000000000002 ***\nas.factor(hour)2    -0.9273089  0.0339990  -27.275 < 0.0000000000000002 ***\nas.factor(hour)3    -1.4043993  0.0408177  -34.407 < 0.0000000000000002 ***\nas.factor(hour)4    -1.4857270  0.0436050  -34.072 < 0.0000000000000002 ***\nas.factor(hour)5    -0.1445565  0.0269275   -5.368         0.0000000795 ***\nas.factor(hour)6     0.7098268  0.0217285   32.668 < 0.0000000000000002 ***\nas.factor(hour)7     1.1810768  0.0200614   58.873 < 0.0000000000000002 ***\nas.factor(hour)8     1.5046904  0.0193702   77.681 < 0.0000000000000002 ***\nas.factor(hour)9     1.2037054  0.0197842   60.842 < 0.0000000000000002 ***\nas.factor(hour)10    1.1446699  0.0197834   57.860 < 0.0000000000000002 ***\nas.factor(hour)11    1.2284903  0.0197093   62.331 < 0.0000000000000002 ***\nas.factor(hour)12    1.3302985  0.0193014   68.922 < 0.0000000000000002 ***\nas.factor(hour)13    1.3132967  0.0195082   67.320 < 0.0000000000000002 ***\nas.factor(hour)14    1.3847953  0.0192934   71.775 < 0.0000000000000002 ***\nas.factor(hour)15    1.4666912  0.0192945   76.016 < 0.0000000000000002 ***\nas.factor(hour)16    1.5718990  0.0189870   82.788 < 0.0000000000000002 ***\nas.factor(hour)17    1.7403120  0.0189307   91.930 < 0.0000000000000002 ***\nas.factor(hour)18    1.4081785  0.0193174   72.897 < 0.0000000000000002 ***\nas.factor(hour)19    1.2683257  0.0194637   65.164 < 0.0000000000000002 ***\nas.factor(hour)20    0.9960781  0.0200791   49.608 < 0.0000000000000002 ***\nas.factor(hour)21    0.8172347  0.0205846   39.701 < 0.0000000000000002 ***\nas.factor(hour)22    0.6961282  0.0211404   32.929 < 0.0000000000000002 ***\nas.factor(hour)23    0.3532942  0.0226143   15.623 < 0.0000000000000002 ***\ndotw_simple2         0.1297790  0.0073219   17.725 < 0.0000000000000002 ***\ndotw_simple3         0.0795613  0.0071602   11.112 < 0.0000000000000002 ***\ndotw_simple4         0.0590945  0.0071312    8.287 < 0.0000000000000002 ***\ndotw_simple5        -0.0254385  0.0072896   -3.490             0.000484 ***\ndotw_simple6        -0.1029802  0.0076764  -13.415 < 0.0000000000000002 ***\ndotw_simple7        -0.1339641  0.0077126  -17.370 < 0.0000000000000002 ***\nTemperature          0.0033083  0.0002215   14.933 < 0.0000000000000002 ***\nPrecipitation       -5.8236111  0.1819010  -32.015 < 0.0000000000000002 ***\nlag1Hour             0.1486368  0.0010467  142.005 < 0.0000000000000002 ***\nlag3Hours            0.0290323  0.0012620   23.005 < 0.0000000000000002 ***\nlag1day              0.0230650  0.0011796   19.554 < 0.0000000000000002 ***\nrolling7day          0.8025392  0.0041082  195.350 < 0.0000000000000002 ***\nsame_hour_last_week  0.0032587  0.0014147    2.304             0.021248 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 680495  on 408551  degrees of freedom\nResidual deviance: 417429  on 408515  degrees of freedom\nAIC: 750707\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n**Answer:**\n\n-   MAE improved slightly from 0.731 to 0.725\n\n# Conclusion\n\n-   We think this model still need to be improved before deploying. The\n    model exhibits higher MAE during peak periods and high demand areas,\n    which is the most tricky parts for rebalanceing. Therefore, the\n    model still struggles to accurately predict these parts with the\n    highest demand.Incorrect use of the model may result in some\n    high-demand stations failing to rebalance in a timely manner,\n    worsening users' experience.We should continuously compare model\n    data with actual conditions to identify stations with low error\n    rates for pilot implementation.\n-   We observe that neighborhoods with higher incomes, lower public\n    transit usage, and higher proportions of white residents exhibit\n    greater MAE. Although these neighborhoods are not traditionally\n    considered disadvantaged communities, the model's inaccuracies can\n    negatively impact the user experience.Some potential users of shared\n    bicycles may be forced to drive due to insufficient bike\n    availability, thereby increasing energy waste. Or deploying large\n    numbers of bikes in car-oriented neighborhoods，which leads to\n    inefficient operations. Field research should be conducted to\n    identify the reasons for discrepancies between predictions and\n    actual conditions.\n-   Error maps show higher MAE in Center City and some outlying\n    high-demand stations, which suggests the model is not fully\n    capturing local land-use patterns or station capacity/nearby station\n    density. Linear effects and mostly may be too simple: true responses\n    to weather, time, and lags are likely non-linear with thresholds and\n    strong interactions. To improve the model performing, we could add\n    more features (like holiday and event calendars, station capacity,\n    distance to CBD) and using more complicated models (non-linear\n    models, machine leraning models).",
    "supporting": [
      "Cen_Yang_Assignment5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}