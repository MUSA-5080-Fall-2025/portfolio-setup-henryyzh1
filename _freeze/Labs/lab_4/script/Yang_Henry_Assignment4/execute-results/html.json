{
  "hash": "3e520213f4f0fb005d827aafcec975fa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 4: Spatial Predictive Analysis\"\nsubtitle: \"Modelling for Chicago Burglaries and 311 Service Request\"\nauthor: \"Henry Yang\"\ndate: 11/05/2025\nformat: \n  html:\n    code-fold: false\n    toc: true\n    toc-location: left\n    theme: cosmo\nexecute:\n  warning: false\n  message: false\n---\n\n## Assignment Overview\n\nIn this lab, you will apply the spatial predictive modeling techniques demonstrated in the class exercise to a 311 service request type of your choice. You will build a complete spatial predictive model, document your process, and interpret your results.\n\n### Learning Goals\n\nBy completing this assignment, you will demonstrate your ability to:\n\n-   Adapt example code to analyze a new dataset\n-   Build spatial features for predictive modeling\n-   Apply count regression techniques to spatial data\n-   Implement spatial cross-validation\n-   Interpret and communicate model results\n-   Critically evaluate model performance\n\n## Step 1: Choose Your 311 Violation Type\n\n### Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ All packages loaded successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Working directory: /Users/henryyang/Desktop/MasterStuff/CPLN5920/Code/portfolio-setup-henryyzh1/Labs/lab_4/script \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Coordinate Reference System\n\nWe're using `ESRI:102271` (Illinois State Plane East, NAD83, US Feet). This is appropriate for Chicago because:\n\n-   It minimizes distortion in this region\n-   Uses feet (common in US planning)\n-   Allows accurate distance calculations\n:::\n\n### Getting the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271', quiet = TRUE) %>%\n  dplyr::select(District = dist_num)\n\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\", quiet = TRUE) %>%\n  st_transform('ESRI:102271', quiet = TRUE) %>%\n  dplyr::select(Beat = beat_num)\n\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\", quiet = TRUE) %>%\n  st_transform('ESRI:102271', quiet = TRUE)\n\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"data\", \"burglaries.shp\"), quiet = TRUE) %>% \n  st_transform('ESRI:102271', quiet = TRUE)\n\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded burglary data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of burglaries: 7482 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - CRS: ESRI:102271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Date range:\", min(burglaries$date, na.rm = TRUE), \"to\", \n    max(burglaries$date, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Date range: Inf to -Inf \n```\n\n\n:::\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nlights_out <- read.csv(here(\"data\",\"311_Alley_Lights_Out.csv\")) %>%\n  filter(!is.na(Longitude), !is.na(Latitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271', quiet = TRUE)\n\n# Check the data\ncat(\"\\n✓ Loaded alley data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded alley data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of lights out reports:\", nrow(lights_out), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of lights out reports: 218912 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - CRS:\", st_crs(lights_out)$input, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - CRS: ESRI:102271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Date range:\", min(lights_out$date, na.rm = TRUE), \"to\", \n    max(lights_out$date, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Date range: Inf to -Inf \n```\n\n\n:::\n:::\n\n\n::: callout-warning\n**Who recorded this data?** Chicago Police Department officers and detectives\n\n**What might be missing?**\n\n-   Unreported burglaries (victims didn't call police)\n-   Incidents police chose not to record\n-   Downgraded offenses (burglary recorded as trespassing)\n-   Spatial bias (more patrol = more recorded crime)\n:::\n\n## Step 2: Complete the Analysis\n\n#### Part 1: Data Loading & Exploration\n\n-   Load your 311 data and Chicago spatial boundaries\n-   Create visualizations showing the spatial distribution of your violation type\n-   Describe patterns you observe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(burglaries)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/visualize-points-1.png){width=960}\n:::\n:::\n\n\n**What I did:** I loaded the Chicago Police Department burglary report dataset and Chicago’s community boundary shapefile. Then, I mapped the raw point locations and created a kernel density surface to visualize spatial intensity.\n\n**Why this matters:** Everything starts from data loading and EPA. Visualizing the raw points and density helps reveal whether reports are randomly distributed or concentrated in particular neighborhoods—an essential foundation before any spatial statistics or modeling.\n\n**What I found:** The burglary reports are not evenly distributed across Chicago. They cluster mainly around West Town, and the South Side, especially in South Shore, and Midway areas.\n\n#### Part 2: Fishnet Grid Creation\n\n-   Create a 500m x 500m fishnet grid\n-   Aggregate your violations to grid cells\n-   Visualize the count distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBurglary count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countBurglaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.042   5.000  40.000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero burglaries: 781 / 2458 ( 31.8 %)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Burglaries\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Burglary Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2017\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/visualize-fishnet-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate lights out reports to fishnet\nreport_fishnet <- st_join(lights_out, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(lights_out = n())\n\n# Join to fishnet\nfishnet <- fishnet %>%\n  left_join(report_fishnet, by = \"uniqueID\") %>%\n  mutate(lights_out = replace_na(lights_out, 0))\n\ncat(\"Lighs out report distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLighs out report distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$lights_out)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   11.00   77.00   89.04  139.00  585.00 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero reports:\", \n    sum(fishnet$lights_out == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$lights_out == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero reports: 362 / 2458 ( 14.7 %)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = lights_out), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"magma\") +\n  labs(title = \"Alleys with Lights Out Reports\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\") +\n  labs(title = \"Burglaries\") +\n  theme_crime()\n\np1 + p2 +\n  plot_annotation(title = \"Are lights out reports and burglaries correlated?\")\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/visualize-reports-1.png){width=960}\n:::\n:::\n\n\n**What I did:** I created a 500 m × 500 m fishnet grid covering Chicago and used a spatial join to aggregate all burglaries reports to their corresponding cells. Then, I visualized the count of reports per grid cell to examine the spatial distribution. Same operations applied to 311 Alleys with Lights Out reports dataset.\n\n**Why this matters:** Using a regular grid standardizes spatial units for later modeling. It avoids biases from administrative boundaries (like MAUP) and allows consistent comparison of event density across space. This aggregation step also prepares the data for spatial statistics (e.g., Local Moran’s I) and regression analysis.\n\n**What I found:** Both datasets are highly skewed and spatially clustered rather than random. For Lights Out reports, counts reach up to 585 per cell, with around 15 % of cells reporting none. For Burglaries, counts peak at 40 per cell, with around 32 % of cells reporting none. Both show overlapping clusters along the South Side areas.\n\n#### Part 3: Spatial Features\n\n-   Calculate k-nearest neighbor features\n-   Perform Local Moran's I analysis\n-   Identify hot spots and cold spots\n-   Create distance-to-hotspot measures\n-   Join any additional contextual data if you are looking for more to do and really get into this (e.g., demographics, land use)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean distance to 3 nearest abandoned cars\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nreports_coords <- st_coordinates(lights_out)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(reports_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    lights_out.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated nearest neighbor distances\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$lights_out.nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   2.711   41.072   68.831  169.671  187.905 1706.739 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to lights out reports\nfishnet <- calculate_local_morans(fishnet, \"lights_out\", k = 5)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Lights Out Reports Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/visualize-morans-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to lights out reports hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to lights out reports hot spots\n  - Number of hot spot cells: 288 \n```\n\n\n:::\n:::\n\n\n**What I did:** I calculated each grid cell’s average distance to its three nearest burglary reports to capture local proximity effects. Then, I used Local Moran’s I to identify statistically significant clusters—High-High (hot spots) and Low-Low (cold spots)—and computed the distance from each cell to the nearest hot spot.\n\n**Why this matters:** These operations are making spatial dependence and neighborhood context quantified. Distance to clusters provides more info than distance to individual points. This reflects how close a location is to areas with systematic problems rather than random incidents. Meanwhile, local Moran’s I measures spatial autocorrelation, revealing patterns of clustering or spatial inequality.\n\n**What I found:** There are about 12% cells are computed as hot spots of burglary reports, which are mainly in the South Side, Midway, and Belmont areas. While Downtown, lake shore, and Marsh Park areas shows large cold-spot zones.\n\n#### Part 4: Count Regression Models\n\n-   Fit Poisson regression\n-   Fit Negative Binomial regression\n-   Compare model fit (AIC)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1708 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    lights_out,\n    lights_out.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Prepared modeling data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 1708 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Variables: 6 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot, family = \"poisson\", data = fishnet_model)\n\nCoefficients:\n                   Estimate  Std. Error z value             Pr(>|z|)    \n(Intercept)      1.62300454  0.04457055  36.414 < 0.0000000000000002 ***\nlights_out       0.00154895  0.00018705   8.281 < 0.0000000000000002 ***\nlights_out.nn   -0.00618865  0.00028226 -21.925 < 0.0000000000000002 ***\ndist_to_hotspot -0.00005536  0.00001040  -5.322          0.000000103 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6710.3  on 1707  degrees of freedom\nResidual deviance: 4740.7  on 1704  degrees of freedom\nAIC: 8809.1\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 3.11 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n\n```{.r .cell-code}\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n⚠ Overdispersion detected! Consider Negative Binomial model.\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot, data = fishnet_model, init.theta = 1.799474553, \n    link = log)\n\nCoefficients:\n                   Estimate  Std. Error z value             Pr(>|z|)    \n(Intercept)      1.62718362  0.08028379  20.268 < 0.0000000000000002 ***\nlights_out       0.00174873  0.00036304   4.817           0.00000146 ***\nlights_out.nn   -0.00686134  0.00041365 -16.587 < 0.0000000000000002 ***\ndist_to_hotspot -0.00004403  0.00001784  -2.468               0.0136 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.7995) family taken to be 1)\n\n    Null deviance: 2690.2  on 1707  degrees of freedom\nResidual deviance: 1801.3  on 1704  degrees of freedom\nAIC: 7418.1\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.799 \n          Std. Err.:  0.104 \n\n 2 x log-likelihood:  -7408.136 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 8809.1 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 7418.1 \n```\n\n\n:::\n:::\n\n\n**What I did:** I joined the Chicago police district boundaries to the fishnet grid and prepared a modeling dataset with 1,708 valid grid cells. Then, I fit both a Poisson regression and a Negative Binomial regression to predict burglary counts using spatial predictors:\n  a) total number of “Lights Out” reports (lights_out),\n  b) mean distance to nearest lights-out reports (lights_out.nn), and\n  c) distance to the nearest lights-out hot spot (dist_to_hotspot).\n\n**Why this matters:** This step tests whether alleys with lights out is spatially associated with burglary occurrence. Poisson regression is a baseline for count data, but when variance exceeds the mean (overdispersion), a Negative Binomial model provides a more realistic fit. Comparing AIC values helps identify the better model.\n\n**What I found:** The Poisson model showed overdispersion (dispersion = 3.11 > 1.5), so the Negative Binomial model was used.\n\t•\tThe coefficient for lights_out is positive and significant, suggesting burglaries increase where more lights-out reports occur.\n\t•\tlights_out.nn and dist_to_hotspot both have negative coefficients, meaning burglaries are less likely where lights-out events are farther away or more dispersed.\n\t•\tModel fit improved substantially (AIC: 8809 -> 7418), confirming that the Negative Binomial regression better explains spatial variation in burglary counts.\n\tTo conclude, burglary risk tends to rise in areas with nearby or clustered lighting outages.\n\n#### Part 5: Spatial Cross-Validation (2017)\n\n-   Implement Leave-One-Group-Out cross-validation on 2017 data\n-   Calculate and report error metrics (MAE, RMSE)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ lights_out + lights_out.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 1.94 \n  Fold 2 / 22 - District 4 - MAE: 1.77 \n  Fold 3 / 22 - District 22 - MAE: 2.26 \n  Fold 4 / 22 - District 6 - MAE: 2.9 \n  Fold 5 / 22 - District 8 - MAE: 3.07 \n  Fold 6 / 22 - District 7 - MAE: 2.99 \n  Fold 7 / 22 - District 3 - MAE: 5.73 \n  Fold 8 / 22 - District 2 - MAE: 2.66 \n  Fold 9 / 22 - District 9 - MAE: 1.86 \n  Fold 10 / 22 - District 10 - MAE: 2.08 \n  Fold 11 / 22 - District 1 - MAE: 1.97 \n  Fold 12 / 22 - District 12 - MAE: 3.01 \n  Fold 13 / 22 - District 15 - MAE: 1.85 \n  Fold 14 / 22 - District 11 - MAE: 2.46 \n  Fold 15 / 22 - District 18 - MAE: 2.54 \n  Fold 16 / 22 - District 25 - MAE: 2.41 \n  Fold 17 / 22 - District 14 - MAE: 2.63 \n  Fold 18 / 22 - District 19 - MAE: 2.1 \n  Fold 19 / 22 - District 16 - MAE: 2.84 \n  Fold 20 / 22 - District 17 - MAE: 1.88 \n  Fold 21 / 22 - District 20 - MAE: 1.88 \n  Fold 22 / 22 - District 24 - MAE: 2.06 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.44 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>LOGO CV Results by District</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fold </th>\n   <th style=\"text-align:left;\"> test_district </th>\n   <th style=\"text-align:right;\"> n_test </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 5.73 </td>\n   <td style=\"text-align:right;\"> 7.75 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:right;\"> 197 </td>\n   <td style=\"text-align:right;\"> 3.07 </td>\n   <td style=\"text-align:right;\"> 4.17 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:left;\"> 12 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 3.01 </td>\n   <td style=\"text-align:right;\"> 4.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:right;\"> 52 </td>\n   <td style=\"text-align:right;\"> 2.99 </td>\n   <td style=\"text-align:right;\"> 3.90 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.90 </td>\n   <td style=\"text-align:right;\"> 4.47 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:left;\"> 16 </td>\n   <td style=\"text-align:right;\"> 129 </td>\n   <td style=\"text-align:right;\"> 2.84 </td>\n   <td style=\"text-align:right;\"> 3.30 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 2.66 </td>\n   <td style=\"text-align:right;\"> 3.59 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 17 </td>\n   <td style=\"text-align:left;\"> 14 </td>\n   <td style=\"text-align:right;\"> 46 </td>\n   <td style=\"text-align:right;\"> 2.63 </td>\n   <td style=\"text-align:right;\"> 4.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> 18 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 2.54 </td>\n   <td style=\"text-align:right;\"> 4.25 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:left;\"> 11 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 2.46 </td>\n   <td style=\"text-align:right;\"> 3.34 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:right;\"> 85 </td>\n   <td style=\"text-align:right;\"> 2.41 </td>\n   <td style=\"text-align:right;\"> 3.32 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> 22 </td>\n   <td style=\"text-align:right;\"> 112 </td>\n   <td style=\"text-align:right;\"> 2.26 </td>\n   <td style=\"text-align:right;\"> 2.74 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> 19 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.10 </td>\n   <td style=\"text-align:right;\"> 2.65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.08 </td>\n   <td style=\"text-align:right;\"> 2.96 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:left;\"> 24 </td>\n   <td style=\"text-align:right;\"> 41 </td>\n   <td style=\"text-align:right;\"> 2.06 </td>\n   <td style=\"text-align:right;\"> 2.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 1.97 </td>\n   <td style=\"text-align:right;\"> 2.63 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 98 </td>\n   <td style=\"text-align:right;\"> 1.94 </td>\n   <td style=\"text-align:right;\"> 2.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:left;\"> 20 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 1.88 </td>\n   <td style=\"text-align:right;\"> 2.27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> 17 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 1.88 </td>\n   <td style=\"text-align:right;\"> 2.27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 1.86 </td>\n   <td style=\"text-align:right;\"> 2.39 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:left;\"> 15 </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 1.85 </td>\n   <td style=\"text-align:right;\"> 2.32 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 235 </td>\n   <td style=\"text-align:right;\"> 1.77 </td>\n   <td style=\"text-align:right;\"> 3.46 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**What I did:** I performed a Leave-One-Group-Out (LOGO) cross-validation by holding out each police district once as the test set while training the Negative Binomial model on the remaining districts. For each fold, I computed Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to assess predictive performance across space.\n\n**Why this matters:** Traditional k-fold CV ignores spatial dependence and can overstate accuracy when nearby observations share information. The LOGO approach enforces spatial independence by testing each district entirely unseen, providing a more realistic evaluation of how well the model generalizes to new geographic areas.\n\n**What I found:** Model performance varied by district — MAE ranged from about 1.8 to 5.7, with the mean MAE = 2.5 and mean RMSE = 3.44. District 3 showed the highest error, indicating local variability not fully captured by the model. Overall, prediction errors remain moderate, suggesting the model can generalize spatially but still struggles in heterogeneous or high-crime areas.\n\n#### Part 6: Model Evaluation\n\n-   Generate final predictions for both years\n-   Compare to KDE baseline\n-   Assess model performance across time\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert lights out reports to ppp (point pattern) format for spatstat\nreports_ppp <- as.ppp(\n  st_coordinates(lights_out),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_reports <- density.ppp(\n  reports_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_reports)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated KDE baseline\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of lights out reports locations\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/visualize-kde-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/compare-models-1.png){width=1152}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> approach </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> model </td>\n   <td style=\"text-align:right;\"> 2.38 </td>\n   <td style=\"text-align:right;\"> 3.48 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> kde </td>\n   <td style=\"text-align:right;\"> 2.55 </td>\n   <td style=\"text-align:right;\"> 3.59 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\", limits = c(0, 30)) +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](Yang_Henry_Assignment4_files/figure-html/prediction-errors-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>Final Negative Binomial Model Coefficients (Exponentiated)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Rate Ratio </th>\n   <th style=\"text-align:right;\"> Std. Error </th>\n   <th style=\"text-align:right;\"> Z </th>\n   <th style=\"text-align:right;\"> P-Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 5.090 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 20.268 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lights_out </td>\n   <td style=\"text-align:right;\"> 1.002 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 4.817 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lights_out.nn </td>\n   <td style=\"text-align:right;\"> 0.993 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> -16.587 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dist_to_hotspot </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> -2.468 </td>\n   <td style=\"text-align:right;\"> 0.014 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Rate ratios &gt; 1 indicate positive association with burglary counts.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n**What I did:** I generated final burglary predictions using the Negative Binomial model and compared them to a KDE (Kernel Density Estimation) baseline that spatially smooths “Lights Out” report locations. Both prediction surfaces were visualized and evaluated using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to assess model accuracy.\n\n**Why this matters:** Comparing a statistical model to a non-parametric spatial baseline (KDE) tests whether incorporating spatial features (e.g., lights-out counts, proximity, hot spot distance) actually improves predictive performance. KDE captures general spatial trends, while the Negative Binomial model adds interpretable structure.\n\n**What I found:** The Negative Binomial model achieved slightly better accuracy (MAE = 2.38, RMSE = 3.48) than the KDE baseline (MAE = 2.55, RMSE = 3.59). Visually, both surfaces capture the same high-risk areas on the South Side, Midway and Belmont areas, but the model better reproduces local variation and avoids the over-smoothing of KDE. Error maps show moderate under-prediction in some high-crime districts and over-prediction in lower-activity zones. This suggests that while the model generalizes well, additional contextual variables could further refine its performance.\n\n# Technical Notes\n\n**Data Sources:**\n\n-   311 Lights Out Reports: https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Alley-Lights-Out-Historical/t28b-ys7j/about_data.\n-   Retrieved via tidycensus R package on 09-24-2025.\n\n**Reproducibility:**\n\n-   All analysis conducted in R version 2025.05.1+513.\n-   Census API key required for replication.\n-   Complete code and documentation available at: https://musa-5080-fall-2025.github.io/portfolio-setup-henryyzh1/.\n",
    "supporting": [
      "Yang_Henry_Assignment4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}